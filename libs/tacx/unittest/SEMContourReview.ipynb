{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os.path\n",
    "sys.path.insert(0, os.getcwd()+\"/..\")\n",
    "from SEMContour import *\n",
    "sys.path.insert(0, os.getcwd()+\"/../../common\")\n",
    "from PlotConfig import *\n",
    "from FileUtil import gpfs2WinPath\n",
    "\n",
    "#CWD = '/gpfs/WW/BD/MXP/SEM_IMAGE/IMEC/Case02_calaveras_v3/3Tmp/CT_KPI_test/Calaveras_v3_regular_CT_KPI_003_slope_modified_revert_all_patterns/h/cache/dummydb/result/MXP/job1/ContourSelectModelCalibration430result1'\n",
    "CWD = r'C:\\Localdata\\D\\Note\\Python\\apps\\MXP\\ContourSelect\\samplejob\\h\\cache\\dummydb\\result\\MXP\\job1\\ContourSelectModelCalibration430result1'\n",
    "#CWD = r'C:\\Localdata\\D\\Note\\Python\\apps\\MXP\\ContourSelect\\samplejob1\\h\\cache\\dummydb\\result\\MXP\\job1\\ContourExtraction400result1'\n",
    "CWD = gpfs2WinPath(CWD)\n",
    "allNeighborColNames = ['NeighborContinuity', 'NeighborOrientation', 'NeighborParalism']\n",
    "\n",
    "class ContourAnalyzer(object):\n",
    "    \"\"\"docstring for ContourData\"\"\"\n",
    "    def __init__(self, contourfile):\n",
    "        self.__build(contourfile)\n",
    "\n",
    "    def __build(self, contourfile):\n",
    "        contour = SEMContour()\n",
    "        contour.parseFile(contourfile)\n",
    "        if not contour:\n",
    "            sys.exit(\"ERROR: read in contour file %s fails\\n\" % contourfile)\n",
    "        self.contour = contour\n",
    "        self.df = contour.toDf()\n",
    "# get contour data\n",
    "patternid = '461'\n",
    "contourfile = os.path.join(CWD, patternid+'_image_contour.txt')\n",
    "ca = ContourAnalyzer(contourfile)\n",
    "df = ca.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_corr(df):\n",
    "    matplotlib.style.use('ggplot')\n",
    "    #plot_contour(self.contour)\n",
    "    # cols = 'slope  ridge_intensity intensity  contrast'.split()\n",
    "    cols = 'slope  ridge_intensity'.split()\n",
    "    print(df.columns)\n",
    "    df = df[cols]\n",
    "    df.loc[:, 'slope'] = df.loc[:, 'slope'].abs().values\n",
    "    \n",
    "    from pandas.plotting import scatter_matrix\n",
    "    colors = ['red','blue']\n",
    "    scatter_matrix(df, alpha=0.2, figsize=(6, 6), diagonal='kde', color=colors) \n",
    "    \n",
    "    '''\n",
    "    import seaborn as sns\n",
    "    sns.set(style=\"ticks\")\n",
    "    sns.pairplot(df, kind='scatter', diag_kind='kde')\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the SEM contour and angle\n",
    "def plot_contour_angle(ca, patternid='', arrow_length=1):\n",
    "    df = ca.df\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect('equal')\n",
    "    imw, imh = ca.contour.getshape()\n",
    "    ax.set_xlim([0, imw])\n",
    "    ax.set_ylim([0, imh])\n",
    "    ax.set_title(\"Pattern \"+patternid+ \" image Contour\")\n",
    "    \n",
    "    # plot image\n",
    "    \n",
    "    # plot contour\n",
    "    ax.plot(df.loc[:, 'offsetx'], df.loc[:, 'offsety'], 'b.')\n",
    "    \n",
    "    # plot angle\n",
    "    for _, row in df.iterrows():\n",
    "        x, y = row.loc['offsetx'], row.loc['offsety']\n",
    "        angle = row.loc['angle']\n",
    "        dx, dy = arrow_length*np.cos(angle), arrow_length*np.sin(angle)\n",
    "        ax.arrow(x, y, dx, dy, width=0.1, fc='y', ec='y') # ,shape='right', overhang=0\n",
    "        \n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "plot_contour_angle(ca, patternid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['polygonId', 'offsetx', 'offsety', 'angle', 'weight', 'confidence',\n",
      "       'intensity', 'slope', 'band_width', 'ridge_intensity', 'curvature',\n",
      "       'contrast', 'mxp_flag', 'EigenRatio', 'UserLabel',\n",
      "       'NeighborOrientation', 'NeighborParalism', 'ClfLabel'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# plot the histgram for the modified slope, & plot by filter\n",
    "print(df.columns)\n",
    "colname = 'slope'\n",
    "df[colname].plot.hist(bins=100)\n",
    "def plot_col_filter(ca, patternid='', colname=''):\n",
    "    df = ca.df\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect('equal')\n",
    "    xini, yini, xend, yend = ca.contour.getBBox()\n",
    "    ax.set_xlim([xini, xend])\n",
    "    ax.set_ylim([yini, yend])\n",
    "    ax.set_title(\"Pattern \"+patternid)\n",
    "    \n",
    "    thresh = 0\n",
    "    flt_gt = df.loc[:, colname] > thresh\n",
    "    flt_eq = df.loc[:, colname] == thresh\n",
    "    flt_lt = df.loc[:, colname] < thresh\n",
    "    \n",
    "    ax.plot(df.loc[flt_gt, 'offsetx'], df.loc[flt_gt, 'offsety'], 'b.', markersize=2, label=colname+'>{}'.format(thresh))\n",
    "    ax.plot(df.loc[flt_eq, 'offsetx'], df.loc[flt_eq, 'offsety'], 'ro', markersize=2, label=colname+'=={}'.format(thresh))\n",
    "    ax.plot(df.loc[flt_lt, 'offsetx'], df.loc[flt_lt, 'offsety'], 'r.', markersize=2, label=colname+'<{}'.format(thresh))\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "plot_col_filter(ca, patternid=patternid, colname=colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot by column unique labels\n",
    "def plot_col_by_label(ca, patternid='', colname=''):\n",
    "    contour = ca.contour\n",
    "    df = ca.df\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect('equal')\n",
    "    xini, yini, xend, yend = contour.getBBox()\n",
    "    ax.set_xlim([xini, xend])\n",
    "    ax.set_ylim([yini, yend])\n",
    "    ax.set_title(\"Pattern \"+patternid)\n",
    "    \n",
    "    uniqVals = df.loc[:, colname].drop_duplicates().values\n",
    "    print(uniqVals)\n",
    "    for label in uniqVals:\n",
    "        flt_eq = df.loc[:, colname] == label\n",
    "        if label == 'nan':\n",
    "            flt_eq = df.loc[:, colname].isna()\n",
    "        ax.plot(df.loc[flt_eq, 'offsetx'], df.loc[flt_eq, 'offsety'], '.', linestyle='None',  markersize=2, label=colname+'=={}'.format(label))\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NeighborContinuity': 'abs(1-NeighborContinuity) > 0.5', 'NeighborOrientation': 'NeighborOrientation<0.98', 'NeighborParalism': 'NeighborParalism<0.98'}\n",
      "      polygonId     offsetx     offsety  NeighborOrientation  NeighborParalism\n",
      "221         3.0  363.509155  358.396942             0.988101          0.993949\n",
      "1155        8.0  569.228882  363.990265             0.999653          0.964964\n",
      "1157        8.0  568.688721  361.937744             0.963027          0.940605\n",
      "1158        8.0  568.573853  360.794159             0.954591          0.931825\n",
      "1159        8.0  568.890320  359.933899             0.999940          0.975617\n",
      "2686       20.0  748.128967  362.925903             0.990697          0.979809\n",
      "2688       20.0  748.586609  363.273712             0.994977          0.942190\n",
      "2689       20.0  748.539124  362.430878             0.993060          0.891079\n",
      "2762       21.0  380.890167  360.028229             0.990474          0.966940\n",
      "2763       21.0  379.944946  359.000275             0.969352          0.878111\n",
      "2828       22.0  554.654602  360.153778             0.995016          0.978308\n",
      "2829       22.0  554.504822  359.288116             0.996310          0.974732\n",
      "3744       25.0  553.985962  607.007751             0.998005          0.972828\n",
      "3746       25.0  554.571655  609.151245             0.995374          0.933155\n",
      "3814       26.0  375.840698  406.217743             0.995925          0.928994\n",
      "3815       26.0  374.985718  406.027771             0.992537          0.930545\n",
      "3920       27.0  756.164795  405.576752             0.995248          0.978019\n",
      "3929       27.0  746.936584  404.893127             0.970391          0.930752\n",
      "4133       27.0  747.455627  608.696777             0.999800          0.922277\n",
      "4134       27.0  747.423096  609.846313             0.964197          0.703807\n",
      "4135       27.0  747.085999  610.985535             0.950756          0.710169\n",
      "4136       27.0  746.909119  612.008301             0.995400          0.939550\n",
      "4143       28.0  365.840454  610.124939             0.999956          0.977738\n",
      "4144       28.0  365.525055  609.430298             0.999850          0.977465\n",
      "4347       28.0  364.702698  406.561737             0.992138          0.911384\n",
      "4349       28.0  366.909424  405.759308             0.992582          0.933946\n",
      "4350       28.0  367.886292  405.602264             0.996903          0.974174\n",
      "4352       28.0  370.033447  405.312592             0.991706          0.962729\n",
      "4353       28.0  370.983185  405.429413             0.991526          0.977485\n",
      "5104       37.0  558.971497  609.080261             0.979147          0.739338\n",
      "5105       37.0  560.012634  608.945862             0.992153          0.887545\n",
      "5106       37.0  561.021851  608.808472             0.993031          0.935764\n",
      "5107       37.0  561.997925  608.682983             0.993759          0.972559\n",
      "5114       37.0  569.126526  607.158142             0.987193          0.962723\n",
      "5216       38.0  748.908752  608.194702             0.987848          0.898637\n",
      "5217       38.0  749.855164  608.397400             0.995638          0.969383\n",
      "5221       38.0  753.994507  608.893188             0.984769          0.971981\n",
      "6895       47.0  757.170227  655.603577             0.994759          0.979455\n",
      "6904       47.0  747.930054  655.914246             0.986614          0.972176\n",
      "7210       48.0  568.227295  655.672668             0.995080          0.961849\n",
      "7212       48.0  566.068237  654.810852             0.993766          0.975991\n",
      "7219       48.0  558.992126  653.973755             0.987458          0.973961\n",
      "7220       48.0  557.928101  653.875244             0.967747          0.926357\n",
      "7221       48.0  556.600037  654.552490             0.956085          0.997041\n",
      "7222       48.0  555.520752  655.613647             0.990175          0.997617\n",
      "7532       49.0  378.553619  657.493164             0.985663          0.968357\n",
      "7533       49.0  377.855103  657.221863             0.995518          0.958850\n",
      "7534       49.0  377.043304  656.913574             0.995349          0.979931\n"
     ]
    }
   ],
   "source": [
    "def addNeighborFeatures(df):\n",
    "    '''\n",
    "    add Features for the input contour DataFrame, based on the neighbor relationship in the context of segment\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: [in, out] contour as DataFrame\n",
    "        [in] Contour df, must contains `polygonId`, `angle`, `offsetx`, `offsety`\n",
    "        [out] Contour df, added `NeighborContinuity`, `NeighborOrientation`, `NeighborParalism`\n",
    "\n",
    "            - `NeighborContinuity`:  |X(n) - X(n-1)|^2, usually is to 1 (because of 8-neighbor contour tracing)\n",
    "            - `NeighborOrientation`:  dot(EigenVector(n), EigenVector(n-1)), closer to 1, the better(may use 1-dot)\n",
    "            - `NeighborParalism`:  ||cross((X(n) - X(n-1)), EigenVector(n-1))||, closer to 1, the better(may use 1-cross)\n",
    "    TODO, the segment neighborhood based features can only be obtained by the whole segment, can't use ROI cropped segment \n",
    "    '''\n",
    "    if len(df) <= 0:\n",
    "        return df\n",
    "    polygonIds = df.loc[:, 'polygonId'].drop_duplicates().values\n",
    "    preIdx = df.index[0]\n",
    "    for polygonId in polygonIds:\n",
    "        isPolygonHead = True\n",
    "        for curIdx, _ in df.loc[df['polygonId']==polygonId, :].iterrows():\n",
    "            NeighborContinuity = 1\n",
    "            NeighborOrientation = 1\n",
    "            NeighborParalism = 1\n",
    "            if not isPolygonHead:\n",
    "                eigenvector_n_1 = np.array([np.cos(df.loc[preIdx, 'angle']), np.sin(df.loc[preIdx, 'angle'])])\n",
    "                eigenvector_n = np.array([np.cos(df.loc[curIdx, 'angle']), np.sin(df.loc[curIdx, 'angle'])])\n",
    "                neighorvector = np.array([df.loc[curIdx, 'offsetx'] - df.loc[preIdx, 'offsetx'],\n",
    "                                        df.loc[curIdx, 'offsety'] - df.loc[preIdx, 'offsety']])\n",
    "                crossvector = np.cross(neighorvector, eigenvector_n_1)\n",
    "\n",
    "                NeighborContinuity = np.sqrt(neighorvector.dot(neighorvector))\n",
    "                NeighborOrientation = eigenvector_n.dot(eigenvector_n_1)\n",
    "                NeighborParalism = np.sqrt(crossvector.dot(crossvector))/NeighborContinuity\n",
    "                NeighborContinuity = NeighborContinuity\n",
    "            preIdx = curIdx\n",
    "            isPolygonHead = False\n",
    "\n",
    "            for ii, val in enumerate([NeighborContinuity, NeighborOrientation, NeighborParalism]):\n",
    "                colname = allNeighborColNames[ii]\n",
    "                df.loc[curIdx, colname] = val\n",
    "    return df\n",
    "\n",
    "def plot_multi_filters(ca, patternid='', strFlts=None, transform_filter=False):\n",
    "    if strFlts is None:\n",
    "        newStrFlts = {}\n",
    "    elif not isinstance(strFlts, dict):\n",
    "        newStrFlts = {}\n",
    "        for col in allNeighborColNames:\n",
    "            for strFlt in strFlts:\n",
    "                if col in strFlt:\n",
    "                    newStrFlts[col] = strFlt\n",
    "                    break\n",
    "    strFlts = newStrFlts\n",
    "    print(strFlts)\n",
    "    df = ca.df\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect('equal')\n",
    "    xini, yini, xend, yend = ca.contour.getBBox()\n",
    "    ax.set_xlim([xini, xend])\n",
    "    ax.set_ylim([yini, yend])\n",
    "    ax.set_title(\"Pattern \"+patternid)\n",
    "    \n",
    "    # plot contour\n",
    "    ax.plot(df.loc[:, 'offsetx'], df.loc[:, 'offsety'], 'k.', markersize=1, label='SEM Contour')\n",
    "    # plot angle\n",
    "    for _, row in df.iterrows():\n",
    "        x, y = row.loc['offsetx'], row.loc['offsety']\n",
    "        angle = row.loc['angle']\n",
    "        arrow_length = 1\n",
    "        dx, dy = arrow_length*np.cos(angle), arrow_length*np.sin(angle)\n",
    "        ax.arrow(x, y, dx, dy, width=0.1, fc='y', ec='y') # ,shape='right', overhang=0\n",
    "\n",
    "    # plot filters\n",
    "    if not transform_filter:\n",
    "        for strFlt in strFlts.values():\n",
    "            curdf = df.query(strFlt)\n",
    "            ax.plot(curdf.loc[:, 'offsetx'], curdf.loc[:, 'offsety'], 'o', markersize=4, label=strFlt, alpha=0.6)\n",
    "    else:\n",
    "        '''\n",
    "        inflection_points = []\n",
    "        for strFlt in strFlts.values():\n",
    "            curdf = df.query(strFlt )\n",
    "            print(strFlt, len(curdf))\n",
    "            if len(curdf) != 0:\n",
    "                inflection_points.append(curdf)\n",
    "        inflection_df = pd.concat(inflection_points)\n",
    "        '''\n",
    "        inflection_df = df.query('or '.join(strFlts.values()))\n",
    "        print(inflection_df[['polygonId', 'offsetx', 'offsety'] + allNeighborColNames[1:]])\n",
    "        \n",
    "        polygonIds = inflection_df.loc[:, 'polygonId'].drop_duplicates().values\n",
    "        for polygonId in polygonIds:\n",
    "            curdf = inflection_df.loc[inflection_df['polygonId']==polygonId, :]\n",
    "            maxNeighborContinuity = curdf.max()['NeighborContinuity']\n",
    "            minNeighborContinuity, minNeighborOrientation, minNeighborParalism = curdf.min()[allNeighborColNames]\n",
    "\n",
    "            if minNeighborParalism < minNeighborOrientation and len(curdf.query(strFlts['NeighborParalism'])) > 0:\n",
    "                idxmin = curdf['NeighborParalism'].idxmin()\n",
    "                ax.plot(curdf.loc[idxmin, 'offsetx'], curdf.loc[idxmin, 'offsety'], 'ro', markersize=4, label='minNeighborParalism', alpha=0.6)\n",
    "            elif minNeighborOrientation < minNeighborParalism and len(curdf.query(strFlts['NeighborOrientation'])) > 0:\n",
    "                idxmin = curdf['NeighborOrientation'].idxmin()\n",
    "                ax.plot(curdf.loc[idxmin, 'offsetx'], curdf.loc[idxmin, 'offsety'], 'rd', markersize=4, label='minNeighborOrientation', alpha=0.6)\n",
    "            elif len(curdf.query(strFlts['NeighborContinuity'])) > 0:\n",
    "                if abs(maxNeighborContinuity-1) > abs(minNeighborContinuity-1):\n",
    "                    idxmax = curdf['NeighborContinuity'].idxmax()\n",
    "                    ax.plot(curdf.loc[idxmax, 'offsetx'], curdf.loc[idxmax, 'offsety'], 'bd', markersize=4, label='maxNeighborContinuity', alpha=0.6)\n",
    "                else:\n",
    "                    idxmin = curdf['NeighborContinuity'].idxmin()\n",
    "                    ax.plot(curdf.loc[idxmin, 'offsetx'], curdf.loc[idxmin, 'offsety'], 'bo', markersize=4, label='minNeighborContinuity', alpha=0.6)\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    inflection_df.plot.scatter(x=allNeighborColNames[1], y=allNeighborColNames[2])\n",
    "    plt.show()\n",
    "\n",
    "df = addNeighborFeatures(df)\n",
    "ca.df = df\n",
    "plot_multi_filters(ca, patternid=patternid, strFlts=['abs(1-NeighborContinuity) > 0.5', 'NeighborParalism<0.98', 'NeighborOrientation<0.98'], transform_filter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25, 0.5, 0.25]\n",
      "21\n",
      "0.0003713524967683643 15\n",
      "8\n",
      "6.26676662872618e-05 18\n",
      "37\n",
      "0.00016929460546810605 12\n",
      "38\n",
      "0.0007485422309084518 6\n"
     ]
    }
   ],
   "source": [
    "def calcMeanOfLargestHistBin(arr, bins=10):\n",
    "    hist, bin_edges = np.histogram(arr, bins=bins)\n",
    "    idxmax = np.argmax(hist)\n",
    "    binvals = arr[np.where(np.logical_and(arr>=bin_edges[idxmax], arr<bin_edges[idxmax+1]))]\n",
    "    return np.mean(binvals)\n",
    "\n",
    "def findIndexOfFirstFlat(arr, gradients=None, start_pos=0, thres=None):\n",
    "    if gradients is None:\n",
    "        gradients = np.gradient(arr, edge_order=2)\n",
    "    assert(len(arr) == len(gradients))\n",
    "    absGradients = np.abs(gradients)\n",
    "    if thres is None:\n",
    "        thres = calcMeanOfLargestHistBin(absGradients)\n",
    "    for ix in range(start_pos, len(gradients)):\n",
    "        if absGradients[ix] < thres:\n",
    "            print(thres, ix)\n",
    "            return ix\n",
    "    return start_pos\n",
    "\n",
    "def findIndexOfFirstZeroCrossing(arr, gradients=None, start_pos=0):\n",
    "    if gradients is None:\n",
    "        gradients = np.gradient(arr, edge_order=2)\n",
    "    assert(len(arr) == len(gradients))\n",
    "    start = start_pos+1 if start_pos == 0 else start_pos\n",
    "    for ix in range(start_pos, len(gradients)):\n",
    "        if gradients[ix]*gradients[ix-1] <=0 :\n",
    "            return ix\n",
    "    return start_pos\n",
    "\n",
    "\n",
    "flt = [0.10650698, 0.78698604, 0.10650698] # sigma = 0.5\n",
    "flt = [0.17, 0.66, 0.17] # sigma 0.6\n",
    "flt = [0.25, 0.5, 0.25] # sigma 0.8\n",
    "print(flt)\n",
    "def smoothSignal(arr):\n",
    "    padArr = np.zeros((arr.shape[0]+2,) )\n",
    "    padArr[0] = arr[0]\n",
    "    padArr[1:-1] = arr\n",
    "    padArr[-1] = arr[-1]\n",
    "    '''\n",
    "    arr = list(arr)\n",
    "    padArr = arr[0:1] + arr[:] + arr[-1:]\n",
    "    '''\n",
    "    newArr = np.convolve(padArr, flt, 'valid')\n",
    "    if len(arr) != len(newArr):\n",
    "        raise ValueError(\"inequal length {} {}\".format(len(arr), len(newArr)))\n",
    "    return newArr\n",
    "\n",
    "for polygonId in [21, 8, 37,  38]: # 27,\n",
    "    print(polygonId)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    curdf = df.loc[df.polygonId==polygonId, :]\n",
    "    x = np.arange(len(curdf))\n",
    "    arr1 = curdf[allNeighborColNames[1]].values\n",
    "    arr2 = curdf[allNeighborColNames[2]].values\n",
    "    #arr2 = smoothSignal(arr2)\n",
    "    gradient1 = np.gradient(arr1, edge_order=2)\n",
    "    gradient2 = np.gradient(arr2, edge_order=2)\n",
    "    Paralism_xx = np.gradient(gradient2, edge_order=2)\n",
    "    \n",
    "    idxmin = np.argmin(arr2)\n",
    "    ax.plot(idxmin, arr2[idxmin], 'o', markersize=12, markeredgewidth=2, markerfacecolor='none', label= 'min'+allNeighborColNames[2])\n",
    "    idx1 = findIndexOfFirstFlat(arr2, gradient2, start_pos=idxmin+1)\n",
    "    idx2 = findIndexOfFirstZeroCrossing(arr2, gradient2, start_pos=idxmin+1)\n",
    "    ax.plot(idx1, arr2[idx1], 'o', markersize=12, markeredgewidth=2, markerfacecolor='none', label= allNeighborColNames[2] + ' zero gradient')\n",
    "    ax.plot(idx2, arr2[idx2], 'o', markersize=12, markeredgewidth=2, markerfacecolor='none', label= allNeighborColNames[2] + ' zero-crossing gradient')\n",
    "    \n",
    "    \n",
    "    #ax.plot(x, (curdf[allNeighborColNames[0]]-1).abs(), 'g-d', label=allNeighborColNames[0])\n",
    "    #ax.plot(x, curdf[allNeighborColNames[1]], '-o', label= allNeighborColNames[1])\n",
    "    ax.plot(x, curdf[allNeighborColNames[2]], '--o', label= allNeighborColNames[2], alpha=0.6)\n",
    "    ax.plot(x, arr2, '--o', label= allNeighborColNames[2], alpha=0.6)\n",
    "    #ax.plot(x, gradient1, '-*', label= allNeighborColNames[1] + ' gradient')\n",
    "    #ax.plot(x, gradient2, '--*', label= allNeighborColNames[2] + ' gradient')\n",
    "    #ax.plot(x, Paralism_xx, '--d', label= allNeighborColNames[2] + ' 2nd deriative')\n",
    "    \n",
    "    if idxmin in range(40):\n",
    "        ax.set_xlim([0, 40])\n",
    "    #plt.yscale('log')    \n",
    "    ax.set_title(\"Pattern {} Vline {}\".format(patternid, polygonId))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peyang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.169398210035925e-05 18\n",
      "8 [['NeighborParalism', 5, 18], None]\n",
      "0.00011158695120658257 20\n",
      "20 [['NeighborParalism', 4, 20], None]\n",
      "0.00017735052081222841 15\n",
      "21 [['NeighborParalism', 5, 15], None]\n",
      "7.852048787687071e-05 18\n",
      "22 [['NeighborParalism', 3, 18], None]\n",
      "7.814207824956477e-05 10\n",
      "25 [None, ['NeighborParalism', 2, 10]]\n",
      "0.0001303466836387707 14\n",
      "26 [None, ['NeighborParalism', 3, 14]]\n",
      "0.00021935529568459545 12\n",
      "27 [None, ['NeighborParalism', 6, 12]]\n",
      "6.290851257767432e-05 7\n",
      "6.290851257767265e-05 21\n",
      "28 [['NeighborParalism', 3, 7], ['NeighborParalism', 9, 21]]\n",
      "0.0002452307144674677 8\n",
      "37 [['NeighborParalism', 2, 8], None]\n",
      "0.00013035268416038056 11\n",
      "38 [['NeighborParalism', 1, 11], None]\n",
      "47 [None, None]\n",
      "48 [None, None]\n",
      "1.666620440009716e-05 17\n",
      "49 [None, ['NeighborParalism', 2, 17]]\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "def categorizeFilters(filters):\n",
    "    if filters is None:\n",
    "        newfilters = {}\n",
    "    elif not isinstance(filters, dict):\n",
    "        newfilters = {}\n",
    "        for col in allNeighborColNames:\n",
    "            for strFlt in filters:\n",
    "                if col in strFlt:\n",
    "                    newfilters[col] = strFlt\n",
    "                    break\n",
    "    filters = newfilters\n",
    "    # print(filters)\n",
    "    return filters\n",
    "\n",
    "def applyNeighborRuleModelPerVLine(linedf, filters, maxTailLenth=20, smooth=True):\n",
    "    dominant_issues = []\n",
    "    linedf.loc[:, 'ClfLabel'] = 1\n",
    "\n",
    "    # step 1, search and apply from head\n",
    "    headdf = linedf.loc[linedf.index[:maxTailLenth], :]\n",
    "    minNeighborOrientation, minNeighborParalism = headdf.min()[allNeighborColNames[1:]]\n",
    "    issue_feature, issue_index = None, None\n",
    "    if minNeighborParalism < minNeighborOrientation and len(headdf.query(filters['NeighborParalism'])) > 0:\n",
    "        issue_feature = 'NeighborParalism'\n",
    "        issue_index = np.argmin(headdf[issue_feature].values)\n",
    "    elif minNeighborOrientation < minNeighborParalism and len(headdf.query(filters['NeighborOrientation'])) > 0:\n",
    "        issue_feature = 'NeighborOrientation'\n",
    "        issue_index = np.argmin(headdf[issue_feature].values)\n",
    "    dominant_issues.append(None)\n",
    "    if issue_feature is not None:\n",
    "        dominant_issues[0] = [issue_feature, issue_index]\n",
    "        arr = linedf[issue_feature].values\n",
    "        if smooth:\n",
    "            arr = smoothSignal(arr)\n",
    "        gradient = np.gradient(arr, edge_order=2)\n",
    "        idxFlat = findIndexOfFirstFlat(arr, gradient, start_pos=issue_index+1)\n",
    "        dominant_issues[0].append(idxFlat)\n",
    "        idxFlat = min(maxTailLenth, idxFlat)\n",
    "        linedf.loc[linedf.index[:idxFlat], 'ClfLabel'] = 0\n",
    "\n",
    "    # step 2, search and apply from tail, reverse order\n",
    "    dominant_issues.append(None)\n",
    "    head_index = 0 if issue_index is None else issue_index\n",
    "    tailrange = len(linedf) - (head_index + 1) # exclude the head issue index itself\n",
    "    if tailrange > maxTailLenth:\n",
    "        taildf = linedf.loc[linedf.index[-maxTailLenth:], :]\n",
    "        minNeighborOrientation, minNeighborParalism = taildf.min()[allNeighborColNames[1:]]\n",
    "        issue_feature, issue_index = None, None\n",
    "        if minNeighborParalism < minNeighborOrientation and len(taildf.query(filters['NeighborParalism'])) > 0:\n",
    "            issue_feature = 'NeighborParalism'\n",
    "            issue_index = np.argmin(taildf[issue_feature].values)\n",
    "            issue_index = maxTailLenth - 1 - issue_index  # use index start from tail\n",
    "        elif minNeighborOrientation < minNeighborParalism and len(taildf.query(filters['NeighborOrientation'])) > 0:\n",
    "            issue_feature = 'NeighborOrientation'\n",
    "            issue_index = np.argmin(taildf[issue_feature].values)\n",
    "            issue_index = maxTailLenth - 1 - issue_index\n",
    "        if issue_feature is not None and issue_index:\n",
    "            dominant_issues[1] = [issue_feature, issue_index]\n",
    "            arr = linedf[issue_feature].values[::-1]\n",
    "            if smooth:\n",
    "                arr = smoothSignal(arr)\n",
    "            gradient = np.gradient(arr, edge_order=2)\n",
    "            idxFlat = findIndexOfFirstFlat(arr, gradient, start_pos=issue_index+1)\n",
    "            dominant_issues[1].append(idxFlat)\n",
    "            idxFlat = min(maxTailLenth, idxFlat)\n",
    "            linedf.loc[linedf.index[-idxFlat:], 'ClfLabel'] = 0\n",
    "    return linedf, dominant_issues\n",
    "\n",
    "def applyNeighborRuleModel(contourdf, filters, smooth=True):\n",
    "    '''\n",
    "    The step to find rule model in python:\n",
    "    1. apply combined filters to find ill contour Vline candidates\n",
    "    2. find the Vline candidates have dominant issues in its head+20 or tail-20\n",
    "    3. remove contour issue head/tail by following rules(default is 3.1):\n",
    "        * 3.1: search start from dominant issue position, new head=Index[1st flat gradient point]\n",
    "        * 3.2: Index[dominant issue position], new head=Index[the gradient zero-crossing point]\n",
    "    '''\n",
    "    maxTailLenth = 20\n",
    "    contourdf.loc[:, 'ClfLabel'] = 1\n",
    "    filters = categorizeFilters(filters)\n",
    "\n",
    "    inflection_df = contourdf.query('or '.join(filters.values()))\n",
    "    # print(inflection_df[['polygonId', 'offsetx', 'offsety'] + allNeighborColNames[1:]])\n",
    "    polygonIds = inflection_df.loc[:, 'polygonId'].drop_duplicates().values\n",
    "    for polygonId in polygonIds:\n",
    "        lineFlt = contourdf['polygonId']==polygonId\n",
    "        linedf = contourdf.loc[lineFlt, :]\n",
    "        newlinedf, dominant_issues = applyNeighborRuleModelPerVLine(linedf, filters, maxTailLenth, smooth)\n",
    "        print(int(polygonId), dominant_issues)\n",
    "        contourdf.loc[lineFlt, :] = newlinedf\n",
    "    return contourdf\n",
    "\n",
    "df = applyNeighborRuleModel(df, ['NeighborOrientation<0.98', 'NeighborParalism<0.98'])\n",
    "ca.df = df\n",
    "#plot_col_filter(ca, patternid='461', colname='ClfLabel')\n",
    "plot_col_by_label(ca, patternid=patternid, colname='ClfLabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot contour filtering by ridge_intensity \n",
    "def plot_rd_filter(ca, patternid=''):\n",
    "    df = ca.df\n",
    "    imw, imh = ca.contour.getshape()\n",
    "    \n",
    "    figw = 9\n",
    "    fig = plt.figure(figsize=(figw, figw))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim([0, imw])\n",
    "    ax.set_ylim([0, imh])\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    thresh = 0.003\n",
    "    flt = df.loc[:, 'ridge_intensity'] > thresh\n",
    "    ax.plot(df.loc[flt, 'offsetx'], df.loc[flt, 'offsety'], 'g.', markersize=2, label='ridge_intensity>{}'.format(thresh))\n",
    "    ax.plot(df.loc[~flt, 'offsetx'], df.loc[~flt, 'offsety'], 'r.', markersize=3, label='ridge_intensity<={}'.format(thresh))\n",
    "    \n",
    "    ax.set_title(patternid+\" Rg>{} filter\".format(thresh))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "plot_rd_filter(ca, 'Pattern 3658')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for pop out plot\n",
    "%matplotlib qt5\n",
    "\n",
    "def plot_reg(ca, winname=''):\n",
    "    df = ca.df\n",
    "    imw, imh = ca.contour.getshape()\n",
    "    \n",
    "    colstr = 'slope  ridge_intensity'\n",
    "    cols = colstr.split()\n",
    "    #df = df[cols]\n",
    "    df.loc[:, 'slope'] = df.loc[:, 'slope'].abs().values\n",
    "    ## df = df.loc[df.slope<0.03, :]\n",
    "    x, y = df.loc[:, 'slope'], df.loc[:, 'ridge_intensity']\n",
    "\n",
    "    # from scipy import stats\n",
    "    # slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "    #plt.plot(x, intercept + slope*x, 'r', label='fitted ridge_intensity')\n",
    "    import statsmodels.api as sm\n",
    "    X = sm.add_constant(x, prepend=False)\n",
    "    results = sm.OLS(y, X).fit()\n",
    "    # print(results.summary())\n",
    "    # print(results.mse_resid, results.mse_total)\n",
    "    # print(results.params, type(results.params))\n",
    "    k, b = results.params.loc['slope'], results.params.loc['const']\n",
    "    \n",
    "    from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "    pred_std, predict_ci_low, predict_ci_upp = wls_prediction_std(results)\n",
    "\n",
    "    xmax, ymax = x.max(), y.max()\n",
    "    figw = 7\n",
    "    fig = plt.figure(figsize=(figw, figw*ymax/xmax))\n",
    "    #fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlim([0, xmax*1.1])\n",
    "    ax.set_ylim([0, ymax*1.1])\n",
    "    \n",
    "    ax.set_title(winname+' ridge_intensity v.s. abs of modified slope')\n",
    "    ax.set_xlabel('modified slope')\n",
    "    ax.set_ylabel('ridge_intensity')\n",
    "    \n",
    "    ax.plot(x, y, 'o', label='original ridge_intensity v.s. slope')\n",
    "    y_pred = results.predict()\n",
    "    ax.plot(x, y_pred, 'r', label='predicted ridge_intensity={:.3f}slope+{:.3f}, $R^2={:.3f}$'.format(k, b, results.rsquared))\n",
    "    plt.plot(x, predict_ci_low, 'b--', lw=1, label='predict lower')\n",
    "    plt.plot(x, predict_ci_upp, 'g--', lw=1, label='predict upper')\n",
    "    \n",
    "    df.loc[:, 'predict_ci_low'] = predict_ci_low\n",
    "    df.loc[:, 'predict_ci_upp'] = predict_ci_upp\n",
    "    \n",
    "    plt.legend()\n",
    "    #plt.show()\n",
    "    \n",
    "    ## ridge_intensity prediction boundary plot\n",
    "    figw = 9\n",
    "    fig = plt.figure(figsize=(2*figw, figw))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    #fig = plt.figure(2)\n",
    "    #ax = fig.add_subplot(111)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim([0, imw])\n",
    "    ax.set_ylim([0, imh])\n",
    "    plt.gca().invert_yaxis()\n",
    "    #ax.set_ylim(ax.get_ylim()[::-1])\n",
    "    \n",
    "    # print(df.columns)\n",
    "    flt = (df.ridge_intensity>=df.predict_ci_low)& (df.ridge_intensity<=df.predict_ci_upp)\n",
    "    nonzero = df.slope != 0\n",
    "    #ax.plot(df.loc[flt ,'offsetx'], 1024-1-df.loc[flt, 'offsety'], 'b.', markersize=3, label='ridge_intensity In prediction range')\n",
    "    ax.plot(df.loc[flt ,'offsetx'], df.loc[flt, 'offsety'], 'b.', markersize=2, label='ridge_intensity In prediction range')\n",
    "    ax.plot(df.loc[(~flt)&nonzero ,'offsetx'], df.loc[(~flt)&nonzero, 'offsety'], 'co', markersize=5, label='Rg Out prediction range, slope!=0')\n",
    "    ax.plot(df.loc[(~flt)&(~nonzero) ,'offsetx'], df.loc[(~flt)&(~nonzero), 'offsety'], 'rd', markersize=5, label='Rg Out prediction range, slope==0')\n",
    "    ax.set_title(winname+\" Rg outside prediction range of $Rg={:.3f}slope+{:.3f}$\".format(k, b))\n",
    "    ax.legend()\n",
    "    \n",
    "    ## ridge_intensity > thresh filter plot\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim([0, imw])\n",
    "    ax.set_ylim([0, imh])\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    thresh = 0.003\n",
    "    flt = df.loc[:, 'ridge_intensity'] > thresh\n",
    "    ax.plot(df.loc[flt, 'offsetx'], df.loc[flt, 'offsety'], 'g.', markersize=2, label='ridge_intensity>{}'.format(thresh))\n",
    "    ax.plot(df.loc[~flt, 'offsetx'], df.loc[~flt, 'offsety'], 'r.', markersize=3, label='ridge_intensity<={}'.format(thresh))\n",
    "    \n",
    "    ax.set_title(winname+\" Rg>{} filter\".format(thresh))\n",
    "    ax.legend()\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    #resid=y-y_pred\n",
    "    #rss=np.sum(resid**2)\n",
    "    #MSE=np.sqrt(rss/(result.nobs-2))\n",
    "    \n",
    "    def ols_quantile(m, X, q):\n",
    "      # m: Statsmodels OLS model.\n",
    "      # X: X matrix of data to predict.\n",
    "      # q: Quantile.\n",
    "      #\n",
    "      from scipy.stats import norm\n",
    "      mean_pred = m.predict(X)\n",
    "      se = np.sqrt(m.scale)\n",
    "      return mean_pred + norm.ppf(q) * se\n",
    "    \n",
    "    #print(ols_quantile(results, X, 0.5))\n",
    "    return results\n",
    "\n",
    "    \n",
    "results = plot_reg(ca)\n",
    "print(\"ridge_intensity v.s. slope regression results:\")\n",
    "print(results.summary())\n",
    "print('\\nresults.mse\\n', results.mse_resid, results.mse_total, '\\n')\n",
    "print(\"results.params\\n\", results.params, type(results.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patterns = [1, 444, 461, 1001, 3658]\n",
    "contourfiles= [CWD+'/{}_image_contour.txt'.format(pid) for pid in patterns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- for slightly better for visualazation\n",
    "\n",
    "    %matplotlib notebook \n",
    "\n",
    "- normal\n",
    "\n",
    "    %matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "### ridge_intensity v.s. slope regression plot for more patterns\n",
    "for ix, contourfile in enumerate(contourfiles):\n",
    "    ca = ContourAnalyzer(contourfile)\n",
    "    iminfo = 'Pattern '+str(patterns[ix])\n",
    "    plot_reg(ca, iminfo)\n",
    "    #plot_rd_filter(ca, iminfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib auto\n",
    "def plot_reg2(df):\n",
    "    colstr = 'slope  ridge_intensity'\n",
    "    cols = colstr.split()\n",
    "    df = df[cols]\n",
    "    df.loc[:, 'slope'] = df.loc[:, 'slope'].abs().values\n",
    "    x, y = df.loc[:, 'slope'], df.loc[:, 'ridge_intensity']\n",
    "\n",
    "    from scipy import stats\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(x, y, 'o', label='original '+colstr)\n",
    "    ax.plot(x, intercept + slope*x, 'r', label='ridge_intensity={:.2f}slope+{:.2f}'.format(slope, intercept))\n",
    "    ax.set_xlim([0, x.max()*1.1])\n",
    "    ax.set_ylabel(r\"ridge_intensity\")\n",
    "    ax.set_xlabel(\"slope\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "plot_reg2(ca.df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

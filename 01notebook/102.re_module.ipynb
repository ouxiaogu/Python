{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subject = '''\n",
    "ID: 1\n",
    "Name: X\n",
    "FamilyN: Y\n",
    "Age: 20\n",
    "\n",
    "ID: 2\n",
    "Name: H\n",
    "FamilyN: F\n",
    "Age: 23\n",
    "\n",
    "ID: 3\n",
    "Name: S\n",
    "FamilyN: Y\n",
    "Age: 13\n",
    "\n",
    "ID: 4\n",
    "Name: M\n",
    "FamilyN: Z\n",
    "Age: 25'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('X', 'Y', '20'), ('H', 'F', '23'), ('S', 'Y', '13'), ('M', 'Z', '25')]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "result = re.findall(\n",
    "    r\"\"\"(?mx)           # multiline, verbose regex\n",
    "    ^ID:.*\\s*           # Match ID: and anything else on that line \n",
    "    Name:\\s*(.*)\\s*     # Match name, capture all characters on this line\n",
    "    FamilyN:\\s*(.*)\\s*  # etc. for family name\n",
    "    Age:\\s*(.*)$        # and age\"\"\", \n",
    "    subject)\n",
    "print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [extract numbers from mixed log file](http://stackoverflow.com/questions/32480483/extract-critical-numbers-from-a-mixed-log-file)\n",
    "\n",
    "\n",
    "I have a log file contained many slices like this:\n",
    "\n",
    "    Align set A and merge into set B ...\n",
    "        setA, 4 images , image size 146 X 131\n",
    "        setA, image 1, shape center shift (7, -9) compared to image center\n",
    "        setA, image 2, shape center shift (8, -10) compared to image center\n",
    "        setA, image 3, shape center shift (6, -9) compared to image center\n",
    "        setA, image 4, shape center shift (6, -8) compared to image center\n",
    "        final set B, image size 143 X 129\n",
    "    Write set B ...\n",
    "\n",
    "Now, I want to extract the numbers in this slice into a table:\n",
    "\n",
    "| width_A | height_A | shift_x | shift_y | width_B | height_B|\n",
    "--- | --- | --- | ----| ---\n",
    "A1 | 146 | 131 | 7 | -9 | 143 | 129\n",
    "A2 | 146 | 131 | 8 | -10 | 143 | 129\n",
    "A3 | 146 | 131 | 6 | -9 | 143 | 129\n",
    "A4 | 146 | 131 | 6 | -8 | 143 | 129\n",
    "\n",
    "| width_A | height_A | shift_x1 | shift_y1 | shift_x2 | shift_y2 | shift_x3 | shift_y3 | shift_x4 | shift_y4 | width_B | height_B|\n",
    "--- | --- | --- | ----| --- | --- | --- | ----| ---| --- | --- | ----|\n",
    "\n",
    "\n",
    "If dividing the procedure into two parts, then:\n",
    "\n",
    "1. text processing, read the text into a dictionary `data`, e.g., `data['A1']['shift_x'] = 7`. \n",
    "2. use pandas convert the dictionary into dataframe: `df = pd.DataFrame(data)`\n",
    "\n",
    "\n",
    "But I am not familiar with python text processing:\n",
    "\n",
    " - Different from [Python: How to loop through blocks of lines](http://stackoverflow.com/questions/3914454/python-how-to-loop-through-blocks-of-lines), my log text are not so well organised; \n",
    " - regular expression may be a choice, but I can never remember the tricks to classify all kinds of symbols\n",
    " \n",
    "Does anyone have a good solution for this? Python is preferred. Thanks in advance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### most tricky part of this script is, ('gauge_no', ) & ('gauge_no') will outcome in different result, first is a turple, 2nd is a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gauge1': {'shift_x3': 13, 'shift_y1': -17, 'shift_y2': -17, 'shift_y3': -17, 'shift_y4': -17, 'height_A': 321, 'height_B': 319, 'shift_x2': 1, 'shift_x4': 14, 'width_B': 263, 'shift_x1': 15, 'width_A': 291}}\n",
      "        height_A  height_B  shift_x1  shift_x2  shift_x3  shift_x4  shift_y1  \\\n",
      "gauge1       321       319        15         1        13        14       -17   \n",
      "\n",
      "        shift_y2  shift_y3  shift_y4  width_A  width_B  width_diff  \\\n",
      "gauge1       -17       -17       -17      291      263          28   \n",
      "\n",
      "        height_diff  \n",
      "gauge1            2  \n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "gauge 1, BWall_01BW90N01920_01720_01320_00440_00960_00860_01320_00440_1_1, processing...\n",
    "Merge set A into set B ...\n",
    "    setA, 4 images , image size 321 X 291\n",
    "    setA, image 1, shape center shift (15, -17) compared to image center\n",
    "    setA, image 2, shape center shift (1, -17) compared to image center\n",
    "    setA, image 3, shape center shift (13, -17) compared to image center\n",
    "    setA, image 4, shape center shift (14, -17) compared to image center\n",
    "    final set B, image size 319 X 263\n",
    "Write gauge 1, set B ...\n",
    "'''\n",
    "\n",
    "# real example 2\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# store attribute as a turple, construct a dictionary, turple_attribute: pattern\n",
    "regexp = {\n",
    "    ('gauge_no', ): re.compile('gauge (\\d{1,}), BWall_.*' ),\n",
    "    ('height_A', 'width_A'): re.compile('\\s+setA, \\d{1,} images , image size (\\d{1,}) X (\\d{1,}).*'),\n",
    "    ('image_no', 'shift_x', 'shift_y'): re.compile('\\s+setA, image (\\d{1,}), shape center shift \\((-?\\d{1,}), (-?\\d{1,})\\) compared to image center.*'),\n",
    "    ('height_B', 'width_B'): re.compile('\\s+final set B, image size (\\d{1,}) X (\\d{1,})')} # ('gauge_no', ): re.compile(r'Write gauge (\\d{1,}), set B.*')\n",
    "    \n",
    "#print(log_file)\n",
    "dict_summary = {}\n",
    "f = text.split('\\n')\n",
    "for line in f:   \n",
    "    #print line\n",
    "    for keys, pattern in regexp.iteritems():\n",
    "        m = pattern.match(line)\n",
    "        if m:          \n",
    "            # traverse attributes\n",
    "            for groupn, attr in enumerate(keys):  \n",
    "                # print attr \n",
    "                if attr == 'gauge_no':\n",
    "                    gauge_no = 'gauge' + str(m.group(groupn+1))\n",
    "                    dict_summary[gauge_no] = {}\n",
    "                elif attr == 'image_no':\n",
    "                    image_no = m.group(groupn+1)\n",
    "                elif (attr == 'shift_x') or (attr == 'shift_y'):\n",
    "                    key = attr + str(image_no)\n",
    "                    dict_summary[gauge_no][key] = int(m.group(groupn+1))\n",
    "                else: # 'height_A', 'width_A', 'height_B', 'width_B'\n",
    "                    dict_summary[gauge_no][attr] = int(m.group(groupn+1))\n",
    "print dict_summary\n",
    "df = pd.DataFrame(dict_summary)\n",
    "df = df.transpose()\n",
    "df['width_diff'] = df.apply(lambda x: x['width_A'] - x['width_B'], axis = 1)\n",
    "df['height_diff'] = df.apply(lambda x: x['height_A'] - x['height_B'], axis = 1)\n",
    "#df.to_csv(os.path.join(workpath, text_path, text_name+'_summary.csv'), sep = ',', na_rep='NaN')\n",
    "print df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2.  multiple matches\n",
    "\n",
    "masksetting = 'PSM:defocus=0.06,PSM:dose=0,PSM:Delta_AI_location=0,binary:defocus=0,binary:dose=0,binary:Delta_AI_location=0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match0 [('PSM', 'defocus', '0.06'), ('PSM', 'dose', '0'), ('PSM', 'Delta_AI_location', '0'), ('binary', 'defocus', '0'), ('binary', 'dose', '0'), ('binary', 'Delta_AI_location', '0')]\n",
      "match2 [('defocus', '0'), ('dose', '0')]\n",
      "match1:  PSM:defocus=0.06, PSM:defocus=0.06, PSM, defocus, 0.06,\n",
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "str1 = 'PSM:defocus=0.06,PSM:dose=0,PSM:Delta_AI_location=0,binary:defocus=0,binary:dose=0,binary:Delta_AI_location=0'\n",
    "str2 = 'defocus=0,dose=0'\n",
    "match0 = re.findall('(?P<{}>[a-zA-Z0-9_]+):(?P<{}>[a-zA-Z0-9_]+)=(?P<{}>[0-9.-]+)'.format( \n",
    "        'Exposure', 'key', 'val' ), str1 )\n",
    "match2 = re.findall('(?P<{}>[a-zA-Z0-9_]+)=(?P<{}>[0-9.-]+)'.format( \n",
    "        'Exposure', 'key', 'val' ), str2 )\n",
    "print \"match0\", match0\n",
    "print \"match2\", match2\n",
    "match1 = re.search('(?P<{}>[a-zA-Z0-9-]+):({})=(?P<{}>[0-9.-]+)'.format( 'Exposure', 'defocus', 'defocus'), str1 )\n",
    "print 'match1: ',match1.group()+',',  match1.group(0)+',',  match1.group(1)+',',  match1.group(2)+',', match1.group(3)+','\n",
    "print type(match2)\n",
    "if not isinstance(match2, list):\n",
    "    printREMatch(match2)\n",
    "    def printREMatch(m):\n",
    "        print len(m.group())\n",
    "        print m.group()\n",
    "        print m.group('defocus')\n",
    "        print m.groups()\n",
    "        print m.groupdict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3. job match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "job0: /gpfs/PEG/FEM/SHARED/NTD_ModelDB/NTDCase56_SEC_10nm_New_tapeout_PRD/temp/Sook_test_TCC/Regular64_05_PTD_Multiple_PRS_3_NTD_FT\n",
      "job1: /gpfs/PEG/FEM/SHARED/NTD_ModelDB/NTDCase56_SEC_10nm_New_tapeout_PRD/temp/Sook_test_TCC/Regular64_03_Optical_PRS_copy_Trunc\n",
      "job2: /gpfs/PEG/FEM/SHARED/NTD_ModelDB/NTDCase56_SEC_10nm_New_tapeout_PRD/temp/Sook_test_TCC/Regular64_03_Optical_PRS_copy_Trunc_FT\n",
      "job3: /gpfs/PEG/FEM/SHARED/NTD_ModelDB/NTDCase56_SEC_10nm_New_tapeout_PRD/temp/Sook_test_TCC/Regular64_03_Optical_PRS_copy_Trunc_FT_NTD\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "print string.punctuation\n",
    "params = 'job0=/gpfs/PEG/FEM/SHARED/NTD_ModelDB/NTDCase56_SEC_10nm_New_tapeout_PRD/temp/Sook_test_TCC/Regular64_05_PTD_Multiple_PRS_3_NTD_FT,job1=/gpfs/PEG/FEM/SHARED/NTD_ModelDB/NTDCase56_SEC_10nm_New_tapeout_PRD/temp/Sook_test_TCC/Regular64_03_Optical_PRS_copy_Trunc,job2=/gpfs/PEG/FEM/SHARED/NTD_ModelDB/NTDCase56_SEC_10nm_New_tapeout_PRD/temp/Sook_test_TCC/Regular64_03_Optical_PRS_copy_Trunc_FT,job3=/gpfs/PEG/FEM/SHARED/NTD_ModelDB/NTDCase56_SEC_10nm_New_tapeout_PRD/temp/Sook_test_TCC/Regular64_03_Optical_PRS_copy_Trunc_FT_NTD'\n",
    "for m in re.findall(r'(\\w+)=([^,=]+)', params): # [^:class:], negated class\n",
    "    print \"%s: %s\" % (m[0].strip(), m[1].strip())\n",
    "#jobpaths = re.findall(r'(?P<{}>[a-zA-Z0-9_/]+)'.format('alias'), params)\n",
    "#print jobpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Model Error', 'Model Error']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stdCol' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4def8fd2372c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mchars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'}'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdCol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mchars\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stdCol' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "chars = '{Model Error} > percentile(75) + 1.5 * IQR or {Model Error} < percentile(25) - 1.5 * IQR'\n",
    "m = re.findall(r'\\{([^*/><+-]+)\\}', chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+47']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "xx = '+47'\n",
    "m = re.findall(r'[+-]?\\d+\\.\\d+|[+-]?\\d+',xx)\n",
    "print m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 512\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "line ='512 512'\n",
    "m = re.search(r'([0-9]+)\\s([0-9]+)', line)            \n",
    "imw=m.group(1)\n",
    "imh=m.group(2)\n",
    "print imw, imh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "job sumbit server config xml match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "leafsevers = \"leaf1, leaf2, leaf3\"\n",
    "leafsevers = '1,4'\n",
    "a = re.findall(r'([^,\\s\\d]+)', leafsevers)\n",
    "print a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. FEM host log processing\n",
    "#### most tricky part of this script is, ('gauge_no', ) & ('gauge_no') will outcome in different result, first is a turple, 2nd is a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     stageIdx  chromNum              rms    attr       parmName       parmVal\n",
      "0           1         5   1.341043020549    mask    InnerCorner          0.02\n",
      "20          1         5   1.341043020549  resist   sigmaCDO1_2d        0.0796\n",
      "40          1         4  1.5960121768596  resist       sigmaAG2         0.063\n",
      "60          1         3  1.7001165659423  resist  r3dShearRatio           0.2\n",
      "80          1         2  1.9592673839835  optics      focusBlur          0.01\n",
      "100         1         1  2.1811642842521    mask    InnerCorner          0.02\n",
      "120         1         1  2.1811642842521  resist   sigmaCDO1_2d        0.0848\n",
      "140         2         2  1.4315225186219  resist       sigmaAG2   0.057421875\n",
      "160         2         4    1.55723335019  resist  r3dShearRatio           0.2\n",
      "180         2         1   1.567419370604  optics      focusBlur          0.01\n",
      "200         2         3  2.0044637717118    mask    InnerCorner          0.02\n",
      "220         2         3  2.0044637717118  resist   sigmaCDO1_2d    0.09484375\n",
      "240         2         5  2.0135507739711  resist       sigmaAG2   0.069921875\n",
      "260         3         2    1.43066678401  resist  r3dShearRatio           0.2\n",
      "280         3         4  1.5402073297239  optics      focusBlur          0.01\n",
      "300         3         1  1.8365538191829    mask    InnerCorner          0.02\n",
      "320         3         1  1.8365538191829  resist   sigmaCDO1_2d    0.08890625\n",
      "340         3         3  1.8917092367892  resist       sigmaAG2  0.0708984375\n",
      "360         3         5  2.1046303307188  resist  r3dShearRatio           0.2\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "log data processing\n",
    "\"\"\"\n",
    "\n",
    "# real example 2\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "hostlog = r'C:\\Localdata\\D\\2Release\\r1612E5.0\\MOD7871_GA\\Benchmark\\lua_host.log'\n",
    "\n",
    "# define 4 regexp formats: parmVals, chromosome N.O.,\n",
    "regexp = {\n",
    "    ('parmValsStart', 'stageIdx'): re.compile(r'<>genetic_algorithm_log, ([a-zA-Z]+), stageIdx\\s*=\\s*([0-9]+)'),\n",
    "    ('chromNum', ): re.compile(r'\\s*([0-9]+)\\s*={' ),\n",
    "    ('attr', ): re.compile(r'\\s+([a-z]+)\\s*={' ),\n",
    "    ('parmName', 'parmVal', ): re.compile(r'\\s+([\\S]+)\\s+=\\s+([0-9.-]+)' ),\n",
    "\n",
    "    ('rmsStart', ): re.compile(r'<>genetic_algorithm_log, ([a-zA-Z]+), rmses =\\s*' ),\n",
    "    ('chromNum', 'rms'): re.compile(r'\\s+([0-9]+)\\s+=\\s+([0-9.]+)'),\n",
    "    ('rmsEnd', ): re.compile(r'AppMain Don([\\w]+)' ),\n",
    "}\n",
    "\n",
    "# read out all the log files\n",
    "populations = {}\n",
    "curAttr = 'NA'\n",
    "columns = ['stageIdx', 'chromNum', 'rms', 'attr', 'parmName', 'parmVal']\n",
    "df = pd.DataFrame()\n",
    "with open(hostlog, 'r') as infile:\n",
    "    # local variables initialization\n",
    "    parmValsStart = False\n",
    "    rmsStart = False\n",
    "    curStageIdx = 0\n",
    "    curChromNum = 0\n",
    "    curAttr = 'NA'\n",
    "    curParmName = 'NA'\n",
    "    curSeries = pd.Series()\n",
    "    curRMS = {}\n",
    "    curdf = pd.DataFrame()\n",
    "\n",
    "    for line in infile.readlines():\n",
    "        #print line\n",
    "        curParmName = 'NA'\n",
    "        for keys, pattern in regexp.iteritems():\n",
    "            m = pattern.match(line)\n",
    "            if m:\n",
    "                # traverse attributes\n",
    "                for groupn, attr in enumerate(keys):\n",
    "                    if attr == 'parmValsStart':\n",
    "                        parmValsStart = True\n",
    "                        curdf = pd.DataFrame()\n",
    "                        curChromNum = 0\n",
    "                    if attr == 'rmsStart':\n",
    "                        parmValsStart = False\n",
    "                        rmsStart = True\n",
    "                        curRMS = {}\n",
    "                    if attr == 'rmsEnd':\n",
    "                        rmsStart = False\n",
    "                        curdf['rms'] = curdf.apply(lambda x: curRMS[x['chromNum']], axis=1)\n",
    "                        df = df.append(curdf)\n",
    "                    if parmValsStart: # if-else order matters\n",
    "                        if attr == 'stageIdx':\n",
    "                            curStageIdx = int(m.group(groupn+1)) # match group content are whole group, val1, val2, ..\n",
    "                        elif attr == 'chromNum':\n",
    "                            curChromNum = int(m.group(groupn+1))\n",
    "                            curAttr = 'NA'\n",
    "                        elif attr == 'attr':\n",
    "                            curAttr = m.group(groupn+1)\n",
    "                        elif attr == 'parmName':\n",
    "                            curParmName = m.group(groupn+1)\n",
    "                        elif attr == 'parmVal':\n",
    "                            curVal = m.group(groupn+1)\n",
    "                            curSeries = pd.Series({'stageIdx': curStageIdx, 'chromNum': curChromNum,\n",
    "                                                 'parmName': curParmName, 'parmVal': curVal, 'attr': curAttr})\n",
    "                            curdf = curdf.append(curSeries, ignore_index=True)\n",
    "                    if rmsStart:\n",
    "                        if attr == 'chromNum':\n",
    "                            curChromNum = int(m.group(groupn+1))\n",
    "                        elif attr == 'rms':\n",
    "                            rms = m.group(groupn+1)\n",
    "                            curRMS[curChromNum] = rms\n",
    "\n",
    "df = df[columns]\n",
    "df = df.sort_values(by=['stageIdx', 'rms', 'attr', 'parmName'])\n",
    "df.index = range(len(df))\n",
    "print df.ix[range(0, len(df), 20), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<>genetic_algorithm_log, AppStage, jobparms = ; AppStage\n",
      "stage GA_Main_Stage_1 params:; 1\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "m = re.match(r'<>genetic_algorithm_log, ([a-zA-Z]+), jobparms\\s*=\\s*', '<>genetic_algorithm_log, AppStage, jobparms = $')\n",
    "print m.group()+';', m.group(1)\n",
    "\n",
    "m = re.match(r'stage GA_Main_Stage_([0-9]+) params:', 'stage GA_Main_Stage_1 params:')\n",
    "print m.group()+';', m.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGS sigmaMGS\n",
      "MGS1 sigmaMGS1\n",
      "Bp1 sigma_bp1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sigmas = ['sigmaMGS', 'sigmaMGS1', 'sigma_bp1']\n",
    "userterms = ['MGS', 'MGS1', 'Bp1']\n",
    "# parmName = ['simgaMGS_shrk', 'sigmaMGS1_dev']\n",
    "# sigmaParms = [aa for aa in parmNames if(re.match(r'sigma[\\S]*', aa) and (not re.match(r'sigma2D[\\S]*', aa)))]\n",
    "# sigmaParms = [aa for aa in parmNames if(re.match(r'sigma[\\S]*', aa) and (not re.match(r'sigma2D[\\S]*', aa)))]\n",
    "for term in userterms:\n",
    "    for sigma in sigmas:\n",
    "        if re.match(r'^sigma_?{}$'.format(term), sigma, re.I) or re.match(r'^sigma_?{}_[\\S]+$'.format(term), sigma, re.I):\n",
    "            print term, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Read the sem point files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEM1 807\n",
      "12700023.548127 15310372.036738\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "lines = ['SEM1 807',\n",
    "'(12700024.243367,15310371.976502) 8.663847 34.717164 -8.631511 0.747836 1.000000 1.000000 12700023.548127 15310372.036738'\n",
    "]\n",
    "\n",
    "for line in lines:\n",
    "    m = re.match(r'^(?P<sem>\\w+)\\s+(?P<npnts>\\d+)$', line)\n",
    "    if m is not None:\n",
    "        semname = m.group('sem')\n",
    "        npnts = m.group('npnts')\n",
    "        idx = 0\n",
    "        print semname, npnts\n",
    "    else:\n",
    "        idx += 1\n",
    "#         mm = re.match(r'^\\((?P<center_x>[0-9.-]+),\\s*(?P<center_y>[0-9.-]+)\\)', line)\n",
    "        mm = re.match(r'^\\([0-9.-]+,[0-9.-]+\\)\\s?[0-9.-]+\\s?[0-9.-]+\\s?[0-9.-]+\\s?[0-9.-]+\\s?[0-9.-]+\\s?[0-9.-]+\\s?(?P<center_x>[0-9.-]+)\\s*(?P<center_y>[0-9.-]+)$', line)\n",
    "#         print mm.group()\n",
    "        print mm.group('center_x'), mm.group('center_y')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Parse Aligned SEM Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEM\tSTATUS\tCOST\tPIXEL\tCENTER_X\tCENTER_Y\tTHETA\n",
      "\n",
      "('SUCCESS', 'COST:31.678214;PIXEL:1.000000;CENTER_X:-10475081.500000;CENTER_Y:-9505384.499977;THETA:0.000000')\n",
      "OrderedDict([('COST', '31.678214'), ('PIXEL', '1.000000'), ('CENTER_X', '-10475081.500000'), ('CENTER_Y', '-9505384.499977'), ('THETA', '0.000000')])\n",
      "1\tSUCCESS\t31.678214\t1.000000\t-10475081.500000\t-9505384.499977\t0.000000\n",
      "\n",
      "('FAILS', 'COST:31.678214;PIXEL:1.000000;CENTER_X:-10475081.500000;CENTER_Y:-9505384.499977;THETA:0.000000')\n",
      "OrderedDict([('COST', '31.678214'), ('PIXEL', '1.000000'), ('CENTER_X', '-10475081.500000'), ('CENTER_Y', '-9505384.499977'), ('THETA', '0.000000')])\n",
      "1\tFAILS\t31.678214\t1.000000\t-10475081.500000\t-9505384.499977\t0.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "\n",
    "def parseKW(s, outtersep=';', innersep=':', dtype=str):\n",
    "    kws = s.split(outtersep)\n",
    "    try:\n",
    "        kws.remove('')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    kws = map(lambda x: map(string.strip, x.split(innersep)), kws)\n",
    "    kws = map(lambda x: (x[0], dtype(x[1])), kws)\n",
    "    return OrderedDict(kws)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    res = 'Aligned Spec: SUCCESS - COST:31.678214;PIXEL:1.000000;CENTER_X:-10475081.500000;CENTER_Y:-9505384.499977;THETA:0.000000\\nAligned Spec: FAILS - COST:31.678214;PIXEL:1.000000;CENTER_X:-10475081.500000;CENTER_Y:-9505384.499977;THETA:0.000000'\n",
    "    keys = ['COST', 'PIXEL', 'CENTER_X', 'CENTER_Y', 'THETA']\n",
    "    \n",
    "    success_pattern = re.compile('^Aligned Spec: (SUCCESS|FAILS) - ([\\w\\d+-.:;]+)')\n",
    "    print('\\t'.join(['SEM', 'STATUS'] + keys) + '\\n')\n",
    "    for line in res.strip().split('\\n'):\n",
    "        semix = '1'\n",
    "        m = re.match(success_pattern, line)\n",
    "        if m is not None:\n",
    "            print m.groups()\n",
    "            kws = parseKW(m.groups()[1])\n",
    "            print kws\n",
    "            print('\\t'.join([semix, m.groups()[0]] + kws.values()) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

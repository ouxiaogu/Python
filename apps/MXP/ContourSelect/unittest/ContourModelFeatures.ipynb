{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, os.path\n",
    "import sys\n",
    "sys.path.insert(0, os.getcwd()+\"/../../../../libs/common\")\n",
    "from FileUtil import gpfs2WinPath\n",
    "\n",
    "caldatafile = r'/gpfs/WW/BD/MXP/SHARED/SEM_IMAGE/IMEC/Case02_calaveras_v3/3Tmp/CT_KPI_test/Calaveras_v3_regular_CT_KPI_003_slope_modified_revert_all_patterns/h/cache/dummydb/result/MXP/job1/ContourSelectModelCalibration430result1/caldata.txt'\n",
    "caldatafile = gpfs2WinPath(caldatafile)\n",
    "\n",
    "df = pd.read_csv(caldatafile, sep='\\s+')\n",
    "\n",
    "tgtColName = 'UserLabel'\n",
    "neighborColNames = ['NeighborOrientation', 'NeighborParalism']#, 'NeighborParalism', 'NeighborContinuity',\n",
    "allColNames = ['NeighborContinuity', 'NeighborOrientation', 'NeighborParalism', 'slope', 'intensity', 'ridge_intensity', 'contrast', 'EigenRatio']\n",
    "srcColNames = ['slope', 'intensity', 'ridge_intensity', 'NeighborOrientation', 'NeighborParalism']\n",
    "tgtColName = 'UserLabel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>slope</th>\n",
       "      <td>-0.001939</td>\n",
       "      <td>0.001602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intensity</th>\n",
       "      <td>0.345614</td>\n",
       "      <td>0.608271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge_intensity</th>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.026195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeighborOrientation</th>\n",
       "      <td>0.934455</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeighborParalism</th>\n",
       "      <td>0.681708</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          min       max\n",
       "slope               -0.001939  0.001602\n",
       "intensity            0.345614  0.608271\n",
       "ridge_intensity      0.000814  0.026195\n",
       "NeighborOrientation  0.934455  1.000000\n",
       "NeighborParalism     0.681708  1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "minMaxScaler = preprocessing.MinMaxScaler()\n",
    "wiScaling = 1\n",
    "\n",
    "if wiScaling:\n",
    "    #################\n",
    "    ## type 1, self implemented scaling\n",
    "     \n",
    "    scaling = lambda X_Arr: np.array([(X_Arr[i] - Xmin[i])/(Xmax[i] - Xmin[i]) for i in range(len(srcColNames)) ]).T\n",
    "    X_cal = df.loc[df.usage=='CAL', srcColNames].values\n",
    "    Xmin = X_cal.min(axis=0)\n",
    "    Xmax = X_cal.max(axis=0)\n",
    "    df.loc[:, srcColNames] = df.loc[:, srcColNames].apply(scaling, axis=1)\n",
    "    '''\n",
    "    #################\n",
    "    \n",
    "    \n",
    "    #################\n",
    "    ## type 2, minmaxScalar\n",
    "    df.loc[:, srcColNames] = minMaxScaler.fit_transform(df.loc[:, srcColNames])\n",
    "    Xmin, Xmax = minMaxScaler.data_min_ , minMaxScaler.data_max_\n",
    "    #################\n",
    "    '''\n",
    "    \n",
    "    # output\n",
    "    dfminmax = pd.DataFrame(data= np.array([Xmin, Xmax]).T, index=srcColNames, columns=['min', 'max'])\n",
    "\n",
    "X_cal = df.loc[df.usage=='CAL', srcColNames].values\n",
    "y_cal = df.loc[df.usage=='CAL', tgtColName].values\n",
    "X_ver = df.loc[df.usage=='VER', srcColNames].values\n",
    "y_ver = df.loc[df.usage=='VER', tgtColName].values\n",
    "dfminmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, srcColNames].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib auto\n",
    "\n",
    "# hist plot \n",
    "\n",
    "df2 = pd.melt(df, id_vars=tgtColName, value_vars=neighborColNames, value_name='value')\n",
    "bins=np.linspace(df2.value.min(), df2.value.max(), 100)\n",
    "g = sns.FacetGrid(df2, col=\"variable\", hue=tgtColName, palette=\"Set1\", col_wrap=3)\n",
    "g.map(plt.hist, 'value', bins=bins, ec=\"k\")\n",
    "plt.yscale('log')\n",
    "g.axes[-1].legend()\n",
    "\n",
    "# scatter plot \n",
    "#sns.pointplot('NeighborOrientation', 'NeighborParalism', hue=tgtColName, data=df)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib auto\n",
    "def sephist(col):\n",
    "    TP = df[df[tgtColName] == 0][col]\n",
    "    TN = df[df[tgtColName] == 1][col]\n",
    "    return TP, TN\n",
    "#df.loc[:, 'slope'] = df.loc[:, 'slope'].abs()\n",
    "for num, alpha in enumerate(allColNames):\n",
    "    plt.subplot(2, 4, num+1)\n",
    "\n",
    "    TP, TN = sephist(alpha)\n",
    "    plt.hist((TP, TN), bins=25, alpha=0.5, label=map(''.join, zip(2*[tgtColName], 2*['=='], ['0', '1'])), color=['b', 'g'])\n",
    "    #plt.hist(TP, bins=50, alpha=0.5, label=tgtColName+'==0', color='b')\n",
    "    #plt.hist(TN, bins=50, alpha=0.5, label=tgtColName+'==1', color='g')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(alpha)\n",
    "    plt.yscale('log')\n",
    "#plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[:, tgtColName].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df[tgtColName]==0, srcColNames].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df[tgtColName]==1, srcColNames].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear', class_weight='balanced') # {0: 10, 1: 1}\n",
    "model = clf.fit(X_cal, y_cal)\n",
    "\n",
    "modelform = pd.DataFrame(data=clf.coef_.flatten(), index=srcColNames)\n",
    "modelform.loc['intercept', 0] = clf.intercept_\n",
    "print(modelform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(random_state=0) # , max_depth=len(srcColNames)+1, min_samples_split=3\n",
    "model = clf.fit(X_cal, y_cal)\n",
    "feature_importance = pd.DataFrame(data=model.feature_importances_.flatten(), index=srcColNames)\n",
    "print(feature_importance)\n",
    "\n",
    "#print(model.decision_path(X_cal))\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz \n",
    "dot_data = tree.export_graphviz(model, out_file=None, \n",
    "                         feature_names=srcColNames,  \n",
    "                         class_names=tgtColName,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True) \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "model = clf.fit(X_cal, y_cal)\n",
    "feature_importance = pd.DataFrame(data=model.feature_importances_.flatten(), index=srcColNames)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "calcRMS = lambda y_pred, y: np.sqrt(np.mean(np.power(y_pred - y, 2)))\n",
    "def predict(X, y, usage='CAL'):\n",
    "    y_pred = model.predict(X)\n",
    "    rms = calcRMS(y_pred, y)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(\"Clf model rms on {} set: {}\".format(usage, rms))\n",
    "    print(\"Clf model confusion matrix on {} set:\\n{}\\n{}\".format(usage, cm, cm_norm))\n",
    "predict(X_cal, y_cal)\n",
    "predict(X_ver, y_ver, 'VER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib auto\n",
    "import sys\n",
    "import os.path\n",
    "sys.path.insert(0, os.getcwd()+\"/../../../../libs/tacx\")\n",
    "print(os.getcwd()+\"/../../../../libs/tacx\")\n",
    "from SEMContour import *\n",
    "sys.path.insert(0, os.getcwd()+\"/../../../../libs/common\")\n",
    "from FileUtil import gpfs2WinPath\n",
    "\n",
    "import glob\n",
    "\n",
    "CWD = ''.join(['/gpfs/WW/BD/MXP/SHARED/SEM_IMAGE/IMEC/Case02_calaveras_v3/3Tmp/CT_KPI_test/Calaveras_v3_regular_CT_KPI_003_slope_modified_revert_all_patterns/'\n",
    "      'h/cache/dummydb/result/MXP/job1/ContourSelectModelCalibration430result1'])\n",
    "\n",
    "''' # comment block 1 starts\n",
    "#################\n",
    "# type 1, review model apply image by random permutation\n",
    "#################\n",
    "pathfilter = '*_image_contour.txt'\n",
    "pathex = gpfs2WinPath(os.path.join(CWD, pathfilter))\n",
    "contourfiles = glob.glob(pathex)\n",
    "contourindice = np.random.permutation(np.arange(len(contourfiles)))\n",
    "for ii in range(0*8, 1*8):\n",
    "    fig = plt.figure()\n",
    "    for jj, idx in enumerate(contourindice[ii*8:(ii+1)*8]):\n",
    "        contourfile = contourfiles[idx]\n",
    "        patternid = os.path.basename(contourfile).strip('_image_contour.txt')\n",
    "        ################# end of type 1\n",
    "''' # comment block 1 ends\n",
    "        \n",
    "#################\n",
    "# type 2, review model apply image by giving list\n",
    "#################\n",
    "patternids = [461, 1001]\n",
    "\n",
    "for ii in range(int(np.ceil(len(patternids)/8.))):\n",
    "    fig = plt.figure()\n",
    "    for jj, idx in enumerate(range(ii*8, (ii+1)*8)):\n",
    "        patternid = str(patternids[idx])\n",
    "        contourfile = gpfs2WinPath(os.path.join(CWD, patternid+'_image_contour.txt'))\n",
    "        ################# end of type 2        \n",
    "        \n",
    "        \n",
    "        if not os.path.exists(contourfile):\n",
    "            print(patternid+' not exist')\n",
    "            continue\n",
    "\n",
    "        class ContourAnalyzer(object):\n",
    "            \"\"\"docstring for ContourData\"\"\"\n",
    "            def __init__(self, contourfile):\n",
    "                self.__build(contourfile)\n",
    "\n",
    "            def __build(self, contourfile):\n",
    "                contour = SEMContour()\n",
    "                contour.parseFile(contourfile)\n",
    "                if not contour:\n",
    "                    sys.exit(\"ERROR: read in contour file %s fails\\n\" % contourfile)\n",
    "                self.contour = contour\n",
    "                self.df = contour.toDf()\n",
    "        # get contour data\n",
    "        ca = ContourAnalyzer(contourfile)\n",
    "        contour = ca.contour\n",
    "        df = ca.df\n",
    "\n",
    "\n",
    "        X_test = df.loc[:, srcColNames].values\n",
    "        X_test = np.array([(X_test[:,i] - Xmin[i])/(Xmax[i] - Xmin[i]) for i in range(len(srcColNames)) ]).T\n",
    "        df.loc[:, 'ClfLabel'] = model.predict(X_test)\n",
    "        # SEM Contour Selection resulst plot: by classifer Positive 0, & Negative 1\n",
    "        def plotContourDiscriminator(contour, im=None, wndname=''):\n",
    "            # plot image and classified contour point\n",
    "            \n",
    "            ax = fig.add_subplot(2,4,jj+1)\n",
    "\n",
    "            imw, imh = contour.getshape()\n",
    "            ax.set_aspect('equal')\n",
    "            '''\n",
    "            ax.set_xlim([0, imw])\n",
    "            ax.set_ylim([0, imh])\n",
    "            '''\n",
    "            xini, yini, xend, yend = contour.getBBox()\n",
    "            ax.set_xlim([xini, xend])\n",
    "            ax.set_ylim([yini, yend])\n",
    "            ax.set_title(wndname)\n",
    "\n",
    "            df = contour.toDf()\n",
    "            Positive = df.ClfLabel==0\n",
    "            Negative = df.ClfLabel==1\n",
    "\n",
    "            # calculate confusion matrix\n",
    "            cm = np.array([len(df.loc[flt, :]) for flt in [Positive, Negative]])\n",
    "            cm_norm = cm.astype('float') / cm.sum()\n",
    "\n",
    "            if im is not None:\n",
    "                ax.imshow(im)\n",
    "            ax.plot(df.loc[Positive ,'offsetx'], df.loc[Positive, 'offsety'], #'b.', markersize=1, \n",
    "                    linestyle='None', marker= 'o', markeredgecolor='r', markersize=2, markeredgewidth=1, markerfacecolor='none', \n",
    "                    label='remove: {}({:.3f}%)'.format(cm[0], cm_norm[0]*100 )) #Discriminator Positive, ClfLabel=0\n",
    "            ax.plot(df.loc[Negative ,'offsetx'], df.loc[Negative, 'offsety'], #'r*', markersize=2,\n",
    "                    linestyle='None', marker= '.', markeredgecolor='b', markersize=2, markeredgewidth=1, markerfacecolor='none', \n",
    "                    label='Keep: {}({:.3f}%)'.format(cm[1], cm_norm[1]*100 )) #Discriminator Negative, ClfLabel=1:\n",
    "\n",
    "            #ax = plt.gca() # gca() function returns the current Axes instance\n",
    "            #ax.set_ylim(ax.get_ylim()[::-1]) # reverse Y\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.legend(loc=1)\n",
    "            plt.show()\n",
    "        plotContourDiscriminator(contour.fromDf(df), wndname='Pattern '+ patternid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
